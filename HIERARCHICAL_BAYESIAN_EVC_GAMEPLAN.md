# Hierarchical Bayesian EVC: Project Gameplan

## Background and Motivation

Executive functioning (EF) involves environment-specific cost-benefit computations about how much cognitive effort is worth applying. Because everyday tasks and environments are dynamic and have element unknown to us, an important factor shaping these computations is uncertainty. This includes uncertainty about the current state, rules to follow, and feedback to guide actions.

The Expected Value of Control (EVC) theory, developed to model how the brain decides when and how much cognitive effort to allocate, has been widely applied in cognitive neuroscience. Traditionally, EVC models have emphasized reward and effort costs but often assume clear and stable task conditions. These don't properly reflect the uncertainty individuals experience while performing tasks. By not taking uncertainty into account, we assume our mental processes are strictly deterministic without any element of being unsure.

To address this limitation, my project integrates Bayesian principles into the EVC framework. Specifically, I propose a EVC model which weighs value assignment with confidence, where determining control allocation is factored in with an individual's moment-to-moment uncertainty and confidence levels. The Bayesian approach provides estimates of confidence that better ground EVC benefit and captures how effort allocation is influenced by the desire for reducing uncertainty.

Uncertainty can be computed in two clear ways. Decision uncertainty can be measured from trial-to-trial variability in evidence clarity or task difficulty. Building upon approaches such as drift diffusion models can allow for confidence estimation based on the likelihood of a correct response on each trial. More ambiguous trials yield higher uncertainty, which can be reduced by investing additional cognitive control.

Second, state or rule uncertainty reflects the uncertainty about task conditions, such as rules or strategies that are ambiguous or might change unexpectedly. Bayesian models allow for estimation of participants' beliefs about the current task rules to follow, and feedback to guide actions. Investing additional cognitive effort can reduce this uncertainty by gathering clearer evidence.

I hypothesize that incorporating this Bayesian uncertainty estimation significantly enhances the predictive and explanatory power of the EVC model. It allows the model to better capture realistic scenarios where uncertainty about rules or evidence fluctuates within tasks. Without this Bayesian component, traditional EVC models fail to account fully for increased control allocation during volatile or ambiguous situations. Bayesian estimation allows better identification or individual differences, clarifying how children vary in their tolerance and response to uncertainty. Implementing Bayesian statistics can introduce certain methodological challenges, such as increased computational complexity and potential difficulties in parameter estimation. To address these challenges, we can consider alternative inference methods, including Markov Chain Monte Carlo (MCMC) sampling of simplified Bayesian approximations, ensuring robust and reliable parameter estimates.

We can vary task clarity (evidence uncertainty) and rule stability (state uncertainty) within validated EF tasks, then test if this uncertainty-aware EVC model better predicts children's behavioral data and neural activity (fNIRS,fMRI) compared to non-Bayesian EVC models.

---

## What the Modeling Specifically Entails

### **Model Architecture: Three-Level Hierarchical Structure**

Our hierarchical Bayesian EVC model operates at three distinct levels, each capturing different sources of variability in cognitive control allocation:

**Level 1 - Population (Group-Level Parameters):**
At the highest level, we estimate parameters that describe the typical child and the variability across children in our sample. These hyperparameters include the mean uncertainty weight (Œº_Œª), which represents how much uncertainty matters for control allocation in the average child, and the between-child standard deviation (œÉ_Œª), which quantifies individual differences. These population-level parameters are estimated with prior distributions: Œº_Œª ~ Normal(0.5, 0.3) and œÉ_Œª ~ HalfNormal(0.2), reflecting our theoretical expectation that uncertainty should matter (centered around 0.5) but allowing the data to inform the final estimate. Similarly, we estimate population-level distributions for reward sensitivity (Œº_Œ≤r, œÉ_Œ≤r), effort cost (Œº_Œ≤e, œÉ_Œ≤e), and baseline control (Œº_baseline, œÉ_baseline).

**Level 2 - Individual (Child-Specific Parameters):**
Each child receives their own set of parameters that are drawn from the population distributions. For example, child i's uncertainty weight Œª·µ¢ is sampled from Normal(Œº_Œª, œÉ_Œª). This means that while each child can have their own unique uncertainty sensitivity, their parameter is constrained by‚Äîand contributes to‚Äîthe group-level distribution. This partial pooling mechanism is critical: children with limited or noisy data have their estimates "shrunk" toward the population mean, preventing extreme or unstable estimates, while children with more informative data retain estimates closer to their individual patterns. The degree of shrinkage is not arbitrary but emerges naturally from the Bayesian framework based on the precision of individual-level versus population-level information.

**Level 3 - Trial (Observation-Level Predictions):**
At the lowest level, for each individual trial, we compute predicted control allocation using the Bayesian EVC formula with the child's individual parameters. Specifically, for trial t of child i, the predicted control is:

```
Control_predicted[i,t] = baseline[i] + 
    (Œ≤_r[i] √ó Reward[t] √ó Accuracy[t] + Œª[i] √ó Uncertainty[t]) / (2 √ó Œ≤_e[i])
```

The observed control (measured via RT, pupil dilation, or neural activity) is then modeled as coming from a normal distribution centered on this prediction with observation noise œÉ_obs:

```
Control_observed[i,t] ~ Normal(Control_predicted[i,t], œÉ_obs)
```

This likelihood function connects our theoretical model to the actual data, allowing us to estimate all parameters simultaneously while properly accounting for measurement noise.

### **Inference via Markov Chain Monte Carlo (MCMC)**

Parameter estimation is conducted using MCMC sampling implemented in PyMC, a modern probabilistic programming framework. Rather than finding single point estimates (as in maximum likelihood), MCMC generates samples from the full posterior distribution P(parameters | data), giving us complete uncertainty quantification for every parameter. We run 4 parallel chains with 2,000 samples each after 1,000 burn-in samples, using the No-U-Turn Sampler (NUTS), an efficient variant of Hamiltonian Monte Carlo. Convergence is assessed via the Gelman-Rubin statistic (RÃÇ < 1.01) and effective sample size (ESS > 400 per parameter). This approach yields not just point estimates but full posterior distributions, allowing us to make probabilistic statements like "the probability that Œº_Œª > 0 is 99.5%", which provides much stronger evidence than traditional p-values.

### **Key Model Parameters and Their Interpretation**

The model estimates several theoretically meaningful parameters:

**Uncertainty Weight (Œª):** This is our primary parameter of interest. It quantifies how much uncertainty affects control allocation. A value of Œª = 0.4 means that a one-unit increase in uncertainty contributes as much to control allocation as a 0.4-unit increase in expected value (reward √ó accuracy). At the population level, Œº_Œª tells us how much uncertainty matters for the typical child. At the individual level, Œª·µ¢ for each child enables us to identify those who are unusually sensitive to uncertainty (high Œª, potentially math-anxious) or unusually insensitive (low Œª, potentially overconfident or impulsive).

**Reward Sensitivity (Œ≤_r):** This parameter captures how much children are motivated by rewards (points, praise, or intrinsic satisfaction). Higher values indicate greater motivation. Individual differences in Œ≤_r can reveal children who are reward-driven versus those who are less motivated by external incentives.

**Effort Cost Weight (Œ≤_e):** This reflects the subjective cost of exerting cognitive control. Higher values mean that control is experienced as more costly or aversive. Children with high Œ≤_e may be prone to mental fatigue or may find effortful tasks particularly draining.

**Baseline Control (baseline):** This represents each child's default level of control allocation before considering task-specific factors like reward or uncertainty. It captures stable individual differences in general engagement or effort investment independent of specific task demands.

### **Model Comparison and Validation**

To rigorously test whether our Bayesian EVC framework provides a better account of children's control allocation than traditional approaches, we compare three nested models:

**Model 1 - Traditional EVC (Baseline):**
```
Control = baseline + (Œ≤_r √ó Reward √ó Accuracy) / (2 √ó Œ≤_e)
```
This model includes reward and effort but no uncertainty term. It serves as our baseline to test whether uncertainty adds predictive value.

**Model 2 - Bayesian EVC (Non-Hierarchical):**
```
Control = baseline + (Œ≤_r √ó Reward √ó Accuracy + Œª √ó Uncertainty) / (2 √ó Œ≤_e)
```
This adds the uncertainty weight Œª but fits a single set of parameters across all children (pooled model), ignoring individual differences.

**Model 3 - Hierarchical Bayesian EVC (Proposed):**
```
Population: Œº_Œª, œÉ_Œª (and hyperparameters for other parameters)
Individual: Œª·µ¢ ~ Normal(Œº_Œª, œÉ_Œª) for each child i
Trial: Control[i,t] using child i's parameters
```
This is our full model with both uncertainty and hierarchical structure.

We compare these models using multiple metrics: Widely Applicable Information Criterion (WAIC), which balances fit and complexity; Leave-One-Out Cross-Validation (LOO-CV), which tests out-of-sample prediction; and posterior predictive checks, which verify that the model can generate data that looks like our actual observations. We expect Model 3 to substantially outperform Model 1 (ŒîWAIC > 20, indicating strong evidence) and moderately outperform Model 2 (ŒîWAIC > 10), demonstrating that both uncertainty and individual differences are critical for understanding control allocation.

### **What the Model Predicts and How We Test It**

The model makes several concrete, testable predictions:

**Prediction 1:** Children allocate more control on high-uncertainty trials. We test this by examining whether Œª > 0 at the population level. A positive uncertainty weight means that, holding reward and accuracy constant, children exert more effort when they are uncertain. We quantify evidence via P(Œº_Œª > 0 | data), expecting this probability to exceed 0.95 (strong evidence) or ideally 0.99 (very strong evidence).

**Prediction 2:** Children vary substantially in their uncertainty sensitivity. We test this by examining œÉ_Œª, the between-child standard deviation of uncertainty weights. If œÉ_Œª is large relative to Œº_Œª (coefficient of variation > 0.3), this indicates meaningful individual differences, justifying the hierarchical structure and suggesting clinical/educational relevance.

**Prediction 3:** Older children show more efficient control allocation (lower Œª). As children develop, they should learn to calibrate control more precisely to task demands rather than over-allocating control due to uncertainty. We test this by correlating individual Œª·µ¢ estimates with age, predicting a negative correlation (r < -0.3).

**Prediction 4:** Children with math anxiety show elevated Œª. Anxiety is characterized by intolerance of uncertainty and overestimation of threat. In our framework, this should manifest as higher uncertainty weights, where anxious children allocate excessive control even when uncertainty is moderate. We test this by comparing Œª between children scoring high versus low on math anxiety questionnaires, predicting Œº_Œª(anxious) > Œº_Œª(control) with posterior probability > 0.95.

By generating quantitative, probabilistic predictions and testing them with rigorous Bayesian inference, our modeling approach provides a principled framework for understanding how uncertainty shapes cognitive control allocation in developing minds, with clear implications for identifying and supporting children who struggle with effortful cognitive tasks.

---

## The Hierarchical Bayesian Advantage for Small Sample Sizes

A critical challenge in cognitive neuroscience research, particularly in developmental and clinical populations, is working with limited sample sizes. Typical in-house studies can realistically recruit 15-30 participants, with 100-200 trials per participant. Traditional pooled models that estimate a single set of parameters across all participants ignore meaningful individual differences and often fail to generalize to new individuals. Conversely, fitting completely separate models for each participant with only 100-200 trials leads to unstable, unreliable parameter estimates with high uncertainty.

Hierarchical Bayesian modeling solves this dilemma through partial pooling‚Äîa principled compromise between complete pooling (treating everyone identically) and no pooling (treating everyone as entirely independent). In hierarchical models, individual-level parameters are constrained by population-level distributions. This means that when data for a particular participant is limited or noisy, their parameter estimates are naturally "shrunk" toward the group mean, stabilizing the estimates. Meanwhile, participants with more informative data retain estimates closer to their individual fits. This shrinkage is not arbitrary; it emerges automatically from the Bayesian framework based on the relative precision of individual versus group-level information.

For our uncertainty weight parameter (Œª), hierarchical Bayesian estimation provides several key advantages. First, we obtain population-level inference: we can estimate the typical uncertainty sensitivity in children (Œº_Œª) and quantify how much children vary in this sensitivity (œÉ_Œª). Second, we obtain stable individual-level estimates (Œª·µ¢ for each child) even with modest trial counts, enabling us to identify which children show atypical patterns‚Äîfor instance, those with unusually high Œª who may be experiencing math anxiety. Third, we can make probabilistic statements such as "the probability that the population mean Œª is greater than zero is 99.8%", providing strong evidence for our theoretical prediction. Finally, the hierarchical structure naturally accommodates missing data and unbalanced designs, making it robust to real-world data collection challenges.

This approach aligns with best practices in contemporary cognitive modeling and computational psychiatry. It maximizes statistical power with limited samples, provides both group-level scientific insight and individual-level clinical utility, and yields interpretable parameters that can guide theoretical understanding and practical interventions. Given the realistic constraints of developmental neuroscience research, hierarchical Bayesian modeling is not merely an option but the optimal methodological choice for testing our uncertainty-aware EVC framework.

---

## Project Gameplan

### **Phase 1: Model Development and Validation (Months 1-3)**

**Objectives:**
1. Implement hierarchical Bayesian EVC in PyMC
2. Validate with simulated data
3. Conduct parameter recovery studies
4. Establish adequate power for planned sample size

**Deliverables:**
- Working hierarchical Bayesian EVC implementation
- Simulation results demonstrating model identifiability
- Power analysis confirming N=30-50 is sufficient
- Preliminary manuscript draft (methods section)

**Code already developed:**
- `models/bayesian_evc.py` - Base model
- `HIERARCHICAL_BAYES_GUIDE.md` - Implementation guide
- `step5_compare_all_models.py` - Model comparison framework

**Remaining tasks:**
- Implement full hierarchical version in PyMC
- Run parameter recovery tests
- Document model specification for methods section

---

### **Phase 2: Pilot Data Collection and Analysis (Months 4-6)**

**Objectives:**
1. Collect pilot data from 10-15 children
2. Test experimental procedures
3. Fit hierarchical model to real data
4. Refine based on pilot results

**Experimental Design:**
- Participants: 10-15 children (ages 8-11)
- Task: Arithmetic problems varying in difficulty (5 levels)
- Trials: 100-150 problems per child
- Measures: RT, accuracy, confidence ratings (1-5 scale)
- Session: ~45 minutes including breaks

**Analysis Plan:**
```python
# Fit hierarchical Bayesian EVC
with pm.Model() as pilot_model:
    # Population-level parameters
    mu_lambda = pm.Normal('mu_lambda', mu=0.5, sigma=0.3)
    sigma_lambda = pm.HalfNormal('sigma_lambda', sigma=0.2)
    
    # Individual parameters (N=10-15)
    lambda_i = pm.Normal('lambda', mu=mu_lambda, sigma=sigma_lambda, shape=n_children)
    
    # ... (full model specification)
    
    trace = pm.sample(2000, tune=1000, chains=4)

# Test primary hypothesis
p_lambda_positive = (trace.posterior['mu_lambda'] > 0).mean()
print(f"P(Œº_Œª > 0) = {p_lambda_positive:.4f}")
```

**Deliverables:**
- Pilot dataset (10-15 children)
- Preliminary parameter estimates
- Proof that Œª > 0 in real data
- Effect size estimates for power analysis
- Refined experimental protocol

---

### **Phase 3: Full Data Collection (Months 7-12)**

**Objectives:**
1. Recruit full sample (N=40-50 children)
2. Collect data using refined protocol
3. Ensure data quality and completeness
4. Preliminary analyses during collection

**Sample Composition:**
- 40-50 children total
- Age range: 7-12 years
- Include range of math abilities
- Screen for math anxiety (optional: recruit anxious subsample for group comparison)

**Data Collection:**
- 150-200 trials per child
- Multiple sessions if needed (reduce fatigue)
- Counterbalanced difficulty presentation
- Collect demographic and clinical questionnaires

**Quality Control:**
- Monitor accuracy rates (should vary with difficulty)
- Check RT distributions (exclude outliers)
- Assess attention/engagement (exclude inattentive participants)
- Track completion rates and dropouts

---

### **Phase 4: Primary Analyses (Months 13-15)**

**Objectives:**
1. Fit hierarchical Bayesian EVC to full dataset
2. Test primary hypotheses
3. Conduct individual differences analyses
4. Model comparison and validation

**Primary Analyses:**

**Analysis 1: Population-level uncertainty effect**
```
H1: Œº_Œª > 0 (uncertainty increases control at population level)

Test: P(Œº_Œª > 0 | data) > 0.95
Expected: Œº_Œª ‚âà 0.35-0.50, strong evidence (P > 0.99)
```

**Analysis 2: Individual differences**
```
H2a: œÉ_Œª > 0 (children vary in uncertainty sensitivity)
H2b: Œª·µ¢ correlates with age (older ‚Üí lower Œª)
H2c: Œª·µ¢ correlates with math anxiety (anxious ‚Üí higher Œª)

Tests:
- Posterior distribution of œÉ_Œª
- Correlation: Œª·µ¢ vs. age
- Correlation: Œª·µ¢ vs. anxiety scores
```

**Analysis 3: Model comparison**
```
H3: Bayesian EVC outperforms Traditional EVC

Metrics:
- WAIC (Widely Applicable Information Criterion)
- LOO-CV (Leave-One-Out Cross-Validation)
- Out-of-sample R¬≤

Expected: ŒîWAIC > 10 (strong evidence for Bayesian)
```

**Analysis 4: Clinical prediction**
```
Exploratory: Can Œª·µ¢ predict math anxiety symptoms?

Analysis:
- Classify children by anxiety (high vs. low)
- Test: Œº_Œª(anxious) > Œº_Œª(control)
- ROC curve: How well does Œª predict anxiety?
```

**Deliverables:**
- Complete statistical results
- Effect sizes and credible intervals
- Individual parameter estimates for each child
- Model comparison table
- Clinical prediction accuracy

---

### **Phase 5: Secondary Analyses and Extensions (Months 16-18)**

**Objectives:**
1. Conduct sensitivity analyses
2. Test alternative model specifications
3. Explore temporal dynamics (if warranted)
4. Prepare supplementary materials

**Secondary Analyses:**

**Sensitivity Analysis 1: Prior robustness**
```python
# Test if results depend on choice of priors
priors = [
    {'mu': 0.3, 'sigma': 0.2},  # Weakly informative
    {'mu': 0.5, 'sigma': 0.5},  # Diffuse
    {'mu': 0.5, 'sigma': 0.1}   # Informative
]

for prior in priors:
    # Refit model
    # Check if Œº_Œª estimate is robust
```

**Sensitivity Analysis 2: Model specification**
```python
# Test alternative cost functions
models = [
    'quadratic_cost',      # control¬≤
    'exponential_cost',    # exp(control)
    'linear_cost'          # control
]
# Compare via WAIC
```

**Exploratory Analysis: Temporal dynamics** (if time permits)
```python
# Add HGF for subset of children with most trials
# Test: Does adding temporal component improve fit?
# Report as exploratory (not primary aim)
```

---

### **Phase 6: Manuscript Preparation (Months 19-21)**

**Objectives:**
1. Write full manuscript
2. Create publication-quality figures
3. Address reviewer comments (internal review)
4. Submit to target journal

**Target Journals (Ranked):**

1. **Tier 1:** *Developmental Science* (IF: 4.5)
   - Perfect fit: Development + computational modeling
   
2. **Tier 2:** *Journal of Educational Psychology* (IF: 5.6)
   - Applied focus on math learning
   
3. **Tier 3:** *Cognitive Development* (IF: 2.5)
   - Computational developmental cognition

**Manuscript Structure:**

**Introduction:**
- EVC framework and its limitations
- Importance of uncertainty in learning
- Developmental changes in control allocation
- Individual differences and math anxiety

**Methods:**
- Participants: N=40-50 children, ages 7-12
- Task: Arithmetic problems, 5 difficulty levels, 150-200 trials
- Model: Hierarchical Bayesian EVC specification
- Analysis: MCMC inference, model comparison

**Results:**
- Primary: Œº_Œª > 0 with strong evidence
- Secondary: Individual differences, developmental changes
- Model comparison: Bayesian >> Traditional

**Discussion:**
- Theoretical: Uncertainty matters for control
- Developmental: Age effects on control efficiency  
- Clinical: Math anxiety and high Œª
- Educational: Personalized difficulty adjustment

---

## Timeline Summary

| Phase | Duration | Key Milestone |
|-------|----------|---------------|
| **1. Development** | Months 1-3 | Validated model + simulation |
| **2. Pilot** | Months 4-6 | Proof of concept (N=10-15) |
| **3. Data Collection** | Months 7-12 | Full dataset (N=40-50) |
| **4. Primary Analysis** | Months 13-15 | Test hypotheses |
| **5. Secondary Analysis** | Months 16-18 | Extensions + robustness |
| **6. Manuscript** | Months 19-21 | Submission |

**Total Duration:** 21 months (~2 years)

---

## Resource Requirements

### **Personnel:**
- PI: 10% effort (supervision, writing)
- Research Assistant: 50% effort (data collection, preprocessing)
- Statistical Consultant: 40 hours (PyMC implementation)

### **Participants:**
- Pilot: 15 children √ó $20 √ó 1 hour = $300
- Full study: 50 children √ó $20 √ó 1.5 hours = $1,500
- **Total: $1,800**

### **Equipment/Software:**
- Eye tracker (optional, for pupil dilation): $5,000-10,000
- Software: Free (Python, PyMC, NumPy, etc.)

### **Other:**
- Conference travel (present results): $2,000
- Publication costs (open access): $2,000

**Total Budget:** $10,000-20,000 (depending on eye tracker)

---

## Success Criteria

### **Minimum Success (Fundable):**
- ‚úÖ Œº_Œª > 0 with P > 0.95 (uncertainty matters)
- ‚úÖ œÉ_Œª > 0 (individual differences exist)
- ‚úÖ Bayesian EVC R¬≤ > Traditional EVC R¬≤

### **Strong Success (High-Impact Journal):**
- ‚úÖ Œº_Œª > 0 with P > 0.99 (very strong evidence)
- ‚úÖ Œª correlates with age or anxiety (r > 0.4)
- ‚úÖ Bayesian EVC R¬≤ > 0.30 (explains 30%+ variance)
- ‚úÖ Clinical prediction: Œª predicts anxiety (AUC > 0.70)

### **Exceptional Success (Nature/Science Track):**
- ‚úÖ All above criteria met
- ‚úÖ Neural validation (fNIRS/fMRI showing Œª correlates with DLPFC)
- ‚úÖ Intervention study (reduce Œª in anxious children)
- ‚úÖ Cross-task generalization (Œª predicts control in other tasks)

---

## Risk Mitigation

### **Risk 1: Small sample size yields unstable estimates**

**Mitigation:**
- Use hierarchical Bayesian modeling (designed for small N)
- Partial pooling stabilizes individual estimates
- Power analysis confirms N=30 adequate for Œº_Œª
- Can always increase N if pilot shows need

**Contingency:** If N=30 insufficient, recruit additional 20 children

---

### **Risk 2: No uncertainty effect (Œª ‚âà 0)**

**Mitigation:**
- Simulation shows Œª > 0 in realistic scenarios
- Prior literature suggests uncertainty matters
- Manipulation check: Vary difficulty to ensure uncertainty range

**Contingency:** Even if Œº_Œª ‚âà 0, still publishable (negative result)
- "Uncertainty does NOT affect control in arithmetic tasks"
- Important theoretical contribution
- Clarifies boundary conditions of EVC

---

### **Risk 3: Model doesn't fit data well (R¬≤ < 0.10)**

**Mitigation:**
- Multiple model specifications tested
- Hierarchical model expected to improve fit substantially
- Validation with simulated data first

**Contingency:** 
- Add temporal dynamics (HGF) as Aim 3
- Integrate with HDDM for richer model
- Still learn about what predicts control (exploratory)

---

### **Risk 4: Computational/technical challenges**

**Mitigation:**
- PyMC has excellent documentation and community
- Statistical consultant budgeted for implementation
- Test on simulated data before real data
- Allow 3 months for model development

**Contingency:**
- Use simpler pooled model if hierarchical too difficult
- Collaborate with computational expert
- Extend timeline if needed

---

## Expected Outcomes and Impact

### **Scientific Impact:**

**Theoretical:**
- Extends foundational EVC framework with uncertainty
- Bridges cognitive control and Bayesian decision theory
- Provides computational account of adaptive control allocation

**Methodological:**
- Demonstrates hierarchical Bayesian approach in developmental EF
- Provides validated model for future researchers
- Open-source implementation for community use

**Empirical:**
- First test of uncertainty-aware EVC in children
- Quantifies individual differences in control allocation
- Developmental trajectory of control efficiency

---

### **Clinical Impact:**

**Assessment:**
- Œª parameter as biomarker for atypical control allocation
- Identify children at risk for math anxiety
- Objective measure vs. subjective questionnaires

**Intervention:**
- Personalized difficulty adjustment (target optimal uncertainty)
- Identify children needing anxiety reduction (high Œª)
- Monitor treatment response via Œª changes

**Prevention:**
- Early identification of maladaptive control patterns
- Tailored educational approaches
- Reduce math anxiety development

---

### **Educational Impact:**

**Adaptive Systems:**
- Use model to select optimal problem difficulty per child
- Balance challenge (learning) with success (confidence)
- Maximize engagement (moderate uncertainty)

**Teacher Training:**
- Understand individual differences in control allocation
- Recognize signs of over-control (anxiety) vs. under-control (disengagement)
- Strategies to support different learner types

**Curriculum Design:**
- Optimal difficulty progression based on uncertainty sensitivity
- Build confidence while maintaining challenge
- Reduce math anxiety through appropriate pacing

---

## Publications and Presentations

### **Publication Plan:**

**Paper 1 (Primary): Hierarchical Bayesian EVC** (Months 19-24)
- *Developmental Science* or *Journal of Educational Psychology*
- Main findings: Œº_Œª > 0, individual differences, developmental changes

**Paper 2 (Extension): Clinical Application** (Months 25-30)
- *Computational Psychiatry* or *Journal of Child Psychology and Psychiatry*
- Focus: Math anxiety and atypical Œª parameters
- Group comparison: Anxious vs. non-anxious

**Paper 3 (Methods): Hierarchical Bayesian Tutorial** (Months 31-36)
- *Behavior Research Methods* or *Psychological Methods*
- Focus: How to implement for cognitive modeling
- Provide open-source code and tutorials

---

### **Presentation Plan:**

**Year 1:**
- Lab meetings: Model development and pilot results
- Departmental seminar: Preliminary findings

**Year 2:**
- Cognitive Science Society: Full results (poster or talk)
- Society for Neuroscience: If neural data collected
- Computational Cognitive Neuroscience: Model-focused presentation

**Year 3:**
- Invited talks: Share completed work and clinical applications

---

## Collaboration Opportunities

### **Within Lab:**

**Labmate using DDM + entropy:**
- Their uncertainty estimates ‚Üí Your EVC model
- Joint paper: "Integrating decision and control models"
- Mutual benefit: Richer analyses for both

**Other lab members:**
- fMRI expertise: Add neural validation
- Clinical expertise: Recruit anxious participants
- Educational: Partner with schools for data collection

---

### **External Collaborations:**

**EVC Researchers:**
- Amitai Shenhav (Brown) - Original EVC theory
- Matthew Botvinick (Google/Princeton) - Cognitive control
- Potential: Get feedback, co-author extensions

**Hierarchical Bayesian Experts:**
- Michael Lee, Jeff Rouder - Bayesian cognitive modeling
- Potential: Methods consultation, validation

**Developmental/Educational:**
- Mathematics education researchers
- Developmental cognitive neuroscientists
- Potential: Access to participant pools, cross-lab validation

---

## Deliverables Checklist

### **Concrete Outputs:**

- [ ] Open-source code repository (GitHub)
- [ ] Simulated dataset with ground truth
- [ ] Real dataset from children (N=40-50)
- [ ] Fitted hierarchical Bayesian model
- [ ] Individual Œª estimates for each child
- [ ] Publication-quality figures (6-8 figures)
- [ ] 3 peer-reviewed publications
- [ ] Tutorial/documentation for future users
- [ ] Clinical assessment tool (Œª measurement protocol)
- [ ] Educational recommendations for adaptive difficulty

---

## Long-Term Vision (Years 2-5)

### **Extensions:**

**Year 2-3: Add Temporal Dynamics**
- Integrate HGF for trial history
- Study learning trajectories
- **Paper 4:** "Temporal dynamics of control allocation"

**Year 3-4: HDDM Integration**
- Combine decision process (HDDM) with control (EVC)
- Comprehensive model
- **Paper 5:** "Integrating decision and control models"

**Year 4-5: Clinical Trial**
- Intervention for high-Œª children
- Test if reducing Œª reduces math anxiety
- **Paper 6:** "Computational intervention for math anxiety"

---

## Why This Gameplan Will Succeed

### **‚úÖ Realistic:**
- Sample sizes achievable (N=30-50)
- Timeline feasible (21 months to first paper)
- Budget reasonable ($10-20K)
- Methods appropriate for sample size

### **‚úÖ Rigorous:**
- Hierarchical Bayesian modeling (state-of-the-art)
- Model comparison and validation
- Sensitivity analyses
- Preregistration (optional but recommended)

### **‚úÖ Impactful:**
- Theoretical contribution (extends EVC)
- Clinical relevance (math anxiety)
- Educational applications (adaptive learning)
- Individual differences (precision education)

### **‚úÖ Focused:**
- One primary model (hierarchical Bayesian EVC)
- Clear hypothesis (Œª > 0)
- Feasible scope (not overambitious)
- Extensions saved for future work

---

## Summary: The Winning Strategy

### **Model Choice:**

**Primary: Hierarchical Bayesian EVC (Non-Temporal)** ‚úÖ

**Why:**
- Perfect complexity-interpretability balance
- Handles small N optimally
- Clear, testable predictions
- Clinical and educational impact
- Fundable and publishable

**Not included (save for later):**
- Temporal dynamics (Paper 2)
- HDDM integration (Paper 3)
- Reservoir computing (not suitable)

---

### **Key Features:**

```
COMPLEXITY: Moderate (reviewers can understand)
    ‚Üì
Hierarchical structure (3 levels)
4 main parameters + 2 hyperparameters
Standard Bayesian inference (MCMC)

INTERPRETABILITY: High (all parameters meaningful)
    ‚Üì
Œº_Œª = "typical child's uncertainty sensitivity"
Œª·µ¢ = "individual child's uncertainty sensitivity"  
Can explain to anyone (clinicians, educators, parents)

FEASIBILITY: High (realistic for 2-year grant)
    ‚Üì
N=40-50 achievable
Timeline: 21 months
Budget: $10-20K
```

---

## Final Recommendation

**For your proposal, use:**

ü•á **Hierarchical Bayesian EVC (Non-Temporal)**

**This maximizes:**
- ‚úÖ Fundability (appropriate complexity)
- ‚úÖ Interpretability (meaningful parameters)  
- ‚úÖ Innovation (extends EVC with uncertainty)
- ‚úÖ Feasibility (realistic sample size and timeline)
- ‚úÖ Impact (theoretical, clinical, educational)

**While avoiding:**
- ‚ùå Too simple (not competitive)
- ‚ùå Too complex (risky, hard to explain)
- ‚ùå Black box (uninterpretable)
- ‚ùå Overambitious (unfocused)

---

**This is your winning proposal strategy!** üèÜ

**You're ready to write a competitive grant with this gameplan!** üìù‚ú®

